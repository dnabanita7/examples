{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "572132fe-28d3-428c-928d-8eb7ed22854d",
   "metadata": {},
   "source": [
    "### Using Decision Tree for Loan Default Prediction\n",
    "\n",
    "### What is our objective ?\n",
    "* To reliably predict wether a person's loan payment will be defaulted based on features such as Salary, Account Balance etc.\n",
    "\n",
    "### Getting to know the dataset!\n",
    "LoanDefault dataset contains historic data for loan defaultees, along with their associated financial background, it has the following features.\n",
    "* Employed - Employment status of the borrower, (1 - Employed | 0 - Unemployed).\n",
    "* Bank Balance - Account Balance of the borrower at the time of repayment / default.\n",
    "* Annual Salary - Per year income of the borrower at the time of repayment / default.\n",
    "* Default - Target variable, indicated if the borrower repayed the loaned amount within the stipulated time period, (1 - Defaulted | 0 - Re-Paid).\n",
    "\n",
    "### Approach\n",
    "* This is an trivial example for dataset containing class imbalance, considering most of the people will be repaying their loan without default.\n",
    "* So, we have to explore our data to check for imbalance, handle it using various techniques.\n",
    "* Explore the correlation between various features in the dataset\n",
    "* Split the preprocessed dataset into train and test sets respectively.\n",
    "* Train a DecisionTree (Classifier) using mlpack.\n",
    "* Finally we'll predict on the test set and using various evaluation metrics such as Accuracy, F1-Score, ROC AUC to judge the performance of our model on unseen data.\n",
    "\n",
    "#### NOTE: In this example we'll be implementing 4 parts i.e modelling on imbalanced, oversampled, SMOTE & undersampled data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feebbb7c-63a5-48f2-a315-cfdf45d42450",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q http://datasets.mlpack.org/LoanDefault.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95cb1c6e-7e25-41d2-bc44-8f01dbf56593",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Import necessary library headers.\n",
    "#include <mlpack/xeus-cling.hpp>\n",
    "#include <mlpack/core.hpp>\n",
    "#include <mlpack/core/data/split_data.hpp>\n",
    "#include <mlpack/methods/decision_tree/decision_tree.hpp>\n",
    "#include <mlpack/core/data/scaler_methods/standard_scaler.hpp>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deed356e-f24d-4f41-8a53-e905a6a28938",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Import utility headers.\n",
    "#define WITHOUT_NUMPY 1\n",
    "#include \"matplotlibcpp.h\"\n",
    "#include \"xwidgets/ximage.hpp\"\n",
    "#include \"../utils/preprocess.hpp\"\n",
    "#include \"../utils/plot.hpp\"\n",
    "\n",
    "namespace plt = matplotlibcpp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4086ed59-0d79-4d6f-8883-d1c7a4658ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace mlpack;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77651c00-9366-4763-be59-04de4fbb469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace mlpack::data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d64f62-b032-473f-a3b0-ac5267777f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace mlpack::tree;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4765a1d2-9bc9-447a-8160-a4411cf76e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Utility functions for evaluation metrics.\n",
    "double Accuracy(const arma::Row<size_t>& yPreds, const arma::Row<size_t>& yTrue)\n",
    "{\n",
    "    const size_t correct = arma::accu(yPreds == yTrue);\n",
    "    return (double)correct / (double)yTrue.n_elem;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cc31d55-dd94-4677-bd88-23ae8df9d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "double Precision(const size_t truePos, const size_t falsePos)\n",
    "{\n",
    "    return (double)truePos / (double)(truePos + falsePos);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f14dd88-24fc-4320-a15c-513081867194",
   "metadata": {},
   "outputs": [],
   "source": [
    "double Recall(const size_t truePos, const size_t falseNeg)\n",
    "{\n",
    "    return (double)truePos / (double)(truePos + falseNeg);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "603a2d02-73b7-44f9-b69e-d9afe52caf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "double F1Score(const size_t truePos, const size_t falsePos, const size_t falseNeg)\n",
    "{\n",
    "    double prec = Precision(truePos, falsePos);\n",
    "    double rec = Recall(truePos, falseNeg);\n",
    "    return 2 * (prec * rec) / (prec + rec);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4807ccd6-d8cc-45cc-be28-3670599b637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "void ClassificationReport(const arma::Row<size_t>& yPreds, const arma::Row<size_t>& yTrue)\n",
    "{\n",
    "    arma::Row<size_t> uniqs = arma::unique(yTrue);\n",
    "    std::cout << std::setw(29) << \"precision\" << std::setw(15) << \"recall\" \n",
    "              << std::setw(15) << \"f1-score\" << std::setw(15) << \"support\" \n",
    "              << std::endl << std::endl;\n",
    "    \n",
    "    for(auto val: uniqs)\n",
    "    {\n",
    "        size_t truePos = arma::accu(yTrue == val && yPreds == val && yPreds == yTrue);\n",
    "        size_t falsePos = arma::accu(yPreds == val && yPreds != yTrue);\n",
    "        size_t trueNeg = arma::accu(yTrue != val && yPreds != val && yPreds == yTrue);\n",
    "        size_t falseNeg = arma::accu(yPreds != val && yPreds != yTrue);\n",
    "        \n",
    "        std::cout << std::setw(15) << val\n",
    "                  << std::setw(12) << std::setprecision(2) << Precision(truePos, falsePos) \n",
    "                  << std::setw(16) << std::setprecision(2) << Recall(truePos, falseNeg) \n",
    "                  << std::setw(14) << std::setprecision(2) << F1Score(truePos, falsePos, falseNeg)\n",
    "                  << std::setw(16) << truePos\n",
    "                  << std::endl;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08db0c0e-c8ab-4f5d-8ba6-4ccfed080ff4",
   "metadata": {},
   "source": [
    "Create a directory named data to store all preprocessed csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c281cdbb-b6b5-4cb5-be9f-e122b75322c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d0bf6-3973-42f9-bf1c-a4ddbe0e4833",
   "metadata": {},
   "source": [
    "Drop the dataset header using sed, sed is an unix utility that prases and transforms text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73a39c05-ffc1-4b11-a015-7376546c54ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat LoanDefault.csv | sed 1d > ./data/LoanDefault_trim.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17f4fd2-f920-45d6-8ba0-79f8a3834a99",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbc75ac3-df70-4eae-843d-fbb0c9d87eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Load the preprocessed dataset into armadillo matrix.\n",
    "arma::mat loanData;\n",
    "data::Load(\"./data/LoanDefault_trim.csv\", loanData);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0bad587-da5d-490d-9156-7a92f1f19c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Employed   Bank Balance  Annual Salary   Defaulted\n",
      "   1.0000e+00   8.7544e+03   5.3234e+05            0\n",
      "            0   9.8062e+03   1.4527e+05            0\n",
      "   1.0000e+00   1.2883e+04   3.8121e+05            0\n",
      "   1.0000e+00   6.3510e+03   4.2845e+05            0\n",
      "   1.0000e+00   9.4279e+03   4.6156e+05            0\n",
      "            0   1.1035e+04   8.9899e+04            0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Inspect the first 5 examples in the dataset\n",
    "std::cout << std::setw(12) << \"Employed\" << std::setw(15) << \"Bank Balance\" << std::setw(15) << \"Annual Salary\" \n",
    "          << std::setw(12) << \"Defaulted\" << std::endl;\n",
    "std::cout << loanData.submat(0, 0, loanData.n_rows-1, 5).t() << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d21336-66df-494a-b27f-24fe093617f0",
   "metadata": {},
   "source": [
    "### Part 1 - Modelling using Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24609a81-22dc-4799-a13c-74179806110e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c8da1cd651478abbd7d60997e230a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: f5c8da1cd651478abbd7d60997e230a6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Visualize the distribution of target classes.\n",
    "CountPlot(\"LoanDefault.csv\", \"Defaulted?\", \"\", \"Part-1 Distribution of target class\");\n",
    "auto img = xw::image_from_file(\"./plots/Part-1 Distribution of target class.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a9481b-0add-4516-a0fd-d3177dfa2611",
   "metadata": {},
   "source": [
    "From the above visualization, we can observe that the presence of \"0\" and \"1\", so there is a huge class imbalance. For the first part we would not be handling the class imbalance. In order to see how our model performs on the raw imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1001ba0-57c0-4bfc-9f76-12b9a245b7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1244ff4bc7b84e65a7bc8ab6f0e4ec0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 1244ff4bc7b84e65a7bc8ab6f0e4ec0d"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Visualize the distibution of target classes with respect to Employment.\n",
    "CountPlot(\"LoanDefault.csv\", \"Defaulted?\", \"Employed\", \"Part-1 Distribution of target class & Employed\");\n",
    "auto img = xw::image_from_file(\"./plots/Part-1 Distribution of target class & Employed.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cfeb07-231b-4d7a-9f22-5424868c10fb",
   "metadata": {},
   "source": [
    "### Visualize Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d11f696-2ee2-4a28-8c2f-1cc1f5abfb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7733405de28f4b488228b6cd126095ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 7733405de28f4b488228b6cd126095ee"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Plot the correlation matrix as heatmap.\n",
    "HeatMapPlot(\"LoanDefault.csv\", \"coolwarm\", \"Part-1 Correlation Heatmap\", 1, 5, 5);\n",
    "auto img = xw::image_from_file(\"./plots/Part-1 Correlation Heatmap.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffd2077c-3b35-4203-9d8b-bb05292a1c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Split the data into features (X) and target (y) variables, targets are the last row.\n",
    "arma::Row<size_t> targets = arma::conv_to<arma::Row<size_t>>::from(loanData.row(loanData.n_rows - 1));\n",
    "// Targets are dropped from the loaded matrix.\n",
    "loanData.shed_row(loanData.n_rows-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333924fb-65af-4d1c-8a5e-d39c8ba1ed02",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "The data set has to be split into a training set and a test set. Here the dataset has 10000 observations and the test Ratio is taken as 25% of the total observations. This indicates the test set should have 25% * 10000 = 2500 observations and trainng test should have 7500 observations respectively. This can be done using the `data::Split()` api from mlpack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7a5a3d3-70c8-4958-8e78-8644bc373838",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Split the dataset into train and test sets using mlpack.\n",
    "arma::mat Xtrain, Xtest;\n",
    "arma::Row<size_t> Ytrain, Ytest;\n",
    "mlpack::data::Split(loanData, targets, Xtrain, Xtest, Ytrain, Ytest, 0.25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2307820-d6d4-436e-bb09-af2d84fb2ef8",
   "metadata": {},
   "source": [
    "### Training Decision Tree model\n",
    "Decision trees start with a basic question, From there you can ask a series of questions to determine an answer. These questions make up the decision nodes in the tree, acting as a means to split the data. Each question helps an individual to arrive at a final decision, which would be denoted by the leaf node. Observations that fit the criteria will follow the “Yes” branch and those that don’t will follow the alternate path.  Decision trees seek to find the best split to subset the data. To create the model we'll be using `DecisionTree<>` API from mlpack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c08855aa-fc82-47d7-aef9-cad5dca04afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create and train Decision Tree model using mlpack.\n",
    "DecisionTree<> dt(Xtrain, Ytrain, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606a2c0-f954-430f-8099-c65594be8689",
   "metadata": {},
   "source": [
    "### Making Predictions on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "788b7c60-f4df-49a4-89b1-45fbd6673fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Classify the test set using trained model & get the probabilities.\n",
    "arma::Row<size_t> output;\n",
    "arma::mat probs;\n",
    "dt.Classify(Xtest, output, probs);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9885e04a-7f31-4f44-a29d-533dd9e32457",
   "metadata": {},
   "source": [
    "### Evaluation metrics\n",
    "\n",
    "* True Positive - The actual value was true & the model predicted true.\n",
    "* False Positive - The actual value was false & the model predicted true, Type I error.\n",
    "* True Negative - The actual value was false & the model predicted false.\n",
    "* False Negative - The actual value was true & the model predicted false, Type II error.\n",
    "\n",
    "`Accuracy`: is a metric that generally describes how the model performs across all classes. It is useful when all classes are of equal importance. It is calculated as the ratio between the number of correct predictions to the total number of predictions.\n",
    "\n",
    "$$Accuracy = \\frac{True_{positive} + True_{negative}}{True_{positive} + True_{negative} + False_{positive} + False_{negative}}$$\n",
    "\n",
    "`Precision`: is calculated as the ratio between the number of positive samples correctly classified to the total number of samples classified as Positive. The precision measures the model's accuracy in classifying a sample as positive.\n",
    "\n",
    "$$Precision = \\frac{True_{positive}}{True_{positive} + False_{positive}}$$\n",
    "\n",
    "`Recall`: is calulated as the ratio between the number of positive samples correctly classified as Positive to the total number of Positive samples. The recall measures the model's ability to detect Positive samples. The higher the recall, the more positive samples detected.\n",
    "\n",
    "$$Recall = \\frac{True_{positive}}{True_{positive} + False_{negative}}$$\n",
    "\n",
    "* The decision of whether to use precision or recall depends on the type of problem begin solved.\n",
    "* If the goal is to detect all positive samples then use recall.\n",
    "* Use precision if the problem is sensitive to classifying a sample as Positive in general.\n",
    "\n",
    "* ROC graph has the True Positive rate on the y axis and the False Positive rate on the x axis.\n",
    "* ROC Area under the curve in the graph is the primary metric to determine if the classifier is doing well, the higher the value the higher the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70f8878c-0b43-4f38-a13d-7d28d8e1a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Save the yTest and probabilities into csv for generating ROC AUC plot.\n",
    "data::Save(\"./data/probabilities.csv\", probs);\n",
    "data::Save(\"./data/ytest.csv\", Ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ba7742c-6cc6-466c-98eb-a32649deb728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9708\n",
      "                    precision         recall       f1-score        support\n",
      "\n",
      "              0        0.98            0.99          0.99            2399\n",
      "              1        0.57            0.35          0.43              28\n"
     ]
    }
   ],
   "source": [
    "// Model evaluation metrics.\n",
    "std::cout << \"Accuracy: \" << Accuracy(output, Ytest) << std::endl;\n",
    "ClassificationReport(output, Ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae7689d2-8af0-4e97-a952-8d6ee93a7435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2301534f91b4d7eb9852f7d6f42df48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: b2301534f91b4d7eb9852f7d6f42df48"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Plot ROC AUC Curve to visualize the performance of the model on TP & FP.\n",
    "RocAucPlot(\"./data/ytest.csv\", \"./data/probabilities.csv\", \"Part-1 Imbalanced Targets ROC AUC Curve\");\n",
    "auto img = xw::image_from_file(\"./plots/Part-1 Imbalanced Targets ROC AUC Curve.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d007a818-7f7b-441f-8354-1b3725745b30",
   "metadata": {},
   "source": [
    "From the above classification report, we can infer that our model trained on imbalanced data performs well on negative class but not the same for positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69a5ca8-70d4-43f6-8f26-8c5289a4df77",
   "metadata": {},
   "source": [
    "### Part 2 - Modelling using Random Oversampling\n",
    "For this part we would be handling the class imbalance. In order to see how our model performs on the randomly oversampled data. We will be using `Resample()` method to oversample the minority class i.e \"1, signifying Defaulted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d189d2fc-944c-4217-a0b2-ce19098244de",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Oversample the minority population.\n",
    "Resample(\"LoanDefault.csv\", \"Defaulted?\", 0, 1, \"oversample\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b1afe87-925f-4cf9-920c-57ff05b39420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd293f0687c4feca705eb9ad3814bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 3dd293f0687c4feca705eb9ad3814bd1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Visualize the distribution of target classes.\n",
    "CountPlot(\"./data/LoanDefault_oversampled.csv\", \"Defaulted?\", \"\", \"Part-2 Distribution of target class\");\n",
    "auto img = xw::image_from_file(\"./plots/Part-2 Distribution of target class.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d05fd-170f-439c-9a02-f0b8309a85dd",
   "metadata": {},
   "source": [
    "From the above plot we can see that after resampling the minority class (Yes) is oversampled to be equal to the majority class (No). This solves our imbalanced data issue for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "058bc1ac-155e-4123-91fd-697eeb05cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./data/LoanDefault_oversampled.csv | sed 1d > ./data/LoanDefault_trim.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "090f7518-88aa-4f9d-8210-8934235e5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Load the preprocessed dataset into armadillo matrix.\n",
    "arma::mat loanData;\n",
    "data::Load(\"./data/LoanDefault_trim.csv\", loanData);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "447f2907-1ad8-4ac1-8ec0-6e26bad2f866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8218673289344ebb98d7237df3cc769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: f8218673289344ebb98d7237df3cc769"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Plot the correlation matrix as heatmap.\n",
    "HeatMapPlot(\"./data/LoanDefault_oversampled.csv\", \"coolwarm\", \"Part-2 Correlation Heatmap\", 1, 5, 5);\n",
    "auto img = xw::image_from_file(\"./plots/Part-2 Correlation Heatmap.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b80f827a-9281-46d5-8800-193d8b292322",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Split the data into features (X) and target (y) variables, targets are the last row.\n",
    "arma::Row<size_t> targets = arma::conv_to<arma::Row<size_t>>::from(loanData.row(loanData.n_rows - 1));\n",
    "// Targets are dropped from the loaded matrix.\n",
    "loanData.shed_row(loanData.n_rows-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948d9979-aad2-46d5-8851-255b98a0913d",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "The dataset has to be split into training and test set. Here the dataset has 19334 observations and the test ratio is taken as 20% of the total observations. This indicates that the test set should have 20% * 19334 = 3866 observations and training set should have 15468 observations respectively. This can be done using the `data::Split()` api from mlpack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7029ca73-6158-411e-9751-97b47e5c1101",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Split the dataset into train and test sets using mlpack.\n",
    "arma::mat Xtrain, Xtest;\n",
    "arma::Row<size_t> Ytrain, Ytest;\n",
    "mlpack::data::Split(loanData, targets, Xtrain, Xtest, Ytrain, Ytest, 0.25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6c2a17-afca-4c7d-9319-e1460892eaa4",
   "metadata": {},
   "source": [
    "### Training Decision Tree model\n",
    "We will use `DecisionTree<>` API from mlpack to train the model on oversampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dbda9f8-fa86-409b-b74a-f9cf2d043c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create and train Decision Tree model using mlpack.\n",
    "DecisionTree<> dt(Xtrain, Ytrain, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8224c0b-60c3-4509-8727-f0baa1a56406",
   "metadata": {},
   "source": [
    "### Making Predictions on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffc86521-76c6-4662-bd8b-2382c8310b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Classify the test set using trained model & get the probabilities.\n",
    "arma::Row<size_t> output;\n",
    "arma::mat probs;\n",
    "dt.Classify(Xtest, output, probs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea48cd29-935d-4b9f-86fb-eb6dca95b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Save the yTest and probabilities into csv for generating ROC AUC plot.\n",
    "data::Save(\"./data/probabilities.csv\", probs);\n",
    "data::Save(\"./data/ytest.csv\", Ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1e2a560-ea33-4ac5-b684-8aede89f2cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "                    precision         recall       f1-score        support\n",
      "\n",
      "              0           1            0.92          0.96            2238\n",
      "              1        0.92               1          0.96            2390\n"
     ]
    }
   ],
   "source": [
    "// Model evaluation metrics.\n",
    "std::cout << \"Accuracy: \" << Accuracy(output, Ytest) << std::endl;\n",
    "ClassificationReport(output, Ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c675da9-554a-40a9-a62a-a4cdc083812b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d9be945f954550b413117bf7ea1e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 44d9be945f954550b413117bf7ea1e41"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Plot ROC AUC Curve to visualize the performance of the model on TP & FP.\n",
    "RocAucPlot(\"./data/ytest.csv\", \"./data/probabilities.csv\", \"Part-2 Random Oversampled Targets ROC AUC Curve\");\n",
    "auto img = xw::image_from_file(\"./plots/Part-2 Random Oversampled Targets ROC AUC Curve.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a2264-d6bc-4d73-8329-ad3026e93e77",
   "metadata": {},
   "source": [
    "From the above classification report, we can infer that our model trained on oversampled data performs well on both the classes, This proves the fact that imbalanced data has affected the model trained in part one. Also from the ROC AUC Curve, we can infer the True Positive Rate is around 99%, which is a good significance that our model performs well on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d033947-8bc7-43c6-8436-c99fde660f92",
   "metadata": {},
   "source": [
    "### Part 3 - Modelling using Synthetic Minority Oversampling Technique\n",
    "For this part we would be handling the class imbalance. In order to see how our model performs on the oversampled data using SMOTE. We will be using `SMOTE` API from imblearn to oversample the minority class i.e \"1, signifying Defaulted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a67a9039-b1eb-4d26-a36e-1997eb5214a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Oversample the minority class using SMOTE resampling strategy.\n",
    "Resample(\"LoanDefault.csv\", \"Defaulted?\", 0, 1, \"smote\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db42d985-524d-428e-bc4e-ed7e04b6aa42",
   "metadata": {},
   "source": [
    "We need to put back the headers manually into the newely sampled dataset for visualization purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33d0451a-7283-4290-aa4a-c0b96db6edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i \"1iEmployed,Bank Balance,Annual Salary,Defaulted?\" ./data/LoanDefault_smotesampled.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "324719a9-b471-46e9-aae6-898b74c80008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac888c2030d41ba9e43cf0f19cca88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 0ac888c2030d41ba9e43cf0f19cca88b"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Visualize the distribution of target classes.\n",
    "CountPlot(\"./data/LoanDefault_smotesampled.csv\", \"Defaulted?\", \"\", \"Part-3 Distribution of target class\");\n",
    "auto img = xw::image_from_file(\"./plots/Part-3 Distribution of target class.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "163310ef-f914-4db4-9d73-3486bf152534",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./data/LoanDefault_smotesampled.csv | sed 1d > ./data/LoanDefault_trim.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7130bb2a-e097-41f8-8c3e-c37f22749bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Load the preprocessed dataset into armadillo matrix.\n",
    "arma::mat loanData;\n",
    "data::Load(\"./data/LoanDefault_trim.csv\", loanData);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad4690e9-20f3-47ca-b178-855c291946cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e57bd3c232c40d7add6e0a2bb72f897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 9e57bd3c232c40d7add6e0a2bb72f897"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Plot the correlation matrix as heatmap.\n",
    "HeatMapPlot(\"./data/LoanDefault_smotesampled.csv\", \"coolwarm\", \"Part-3 Correlation Heatmap\", 1, 5, 5);\n",
    "auto img = xw::image_from_file(\"./plots/Part-3 Correlation Heatmap.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1adbc6f8-ad80-4026-b450-9c1e0955fed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Split the data into features (X) and target (y) variables, targets are the last row.\n",
    "arma::Row<size_t> targets = arma::conv_to<arma::Row<size_t>>::from(loanData.row(loanData.n_rows - 1));\n",
    "// Targets are dropped from the loaded matrix.\n",
    "loanData.shed_row(loanData.n_rows-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d5f28c-36c6-4c16-8805-00c3eb3bfeac",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "The dataset has to be split into training and test set. The test ratio is taken as 25% of the total observations. This can be done using the `data::Split()` api from mlpack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31643228-6f86-4729-af8e-372e858f3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Split the dataset into train and test sets using mlpack.\n",
    "arma::mat Xtrain, Xtest;\n",
    "arma::Row<size_t> Ytrain, Ytest;\n",
    "mlpack::data::Split(loanData, targets, Xtrain, Xtest, Ytrain, Ytest, 0.25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc197a48-6c92-47a7-9812-85a1fff8be73",
   "metadata": {},
   "source": [
    "### Training Decision Tree model\n",
    "We will use `DecisionTree<>` API from mlpack to train the model on SMOTE data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44e7aa37-a8e0-4062-88e6-c72d60283eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create and train Decision Tree model.\n",
    "DecisionTree<> dt(Xtrain, Ytrain, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fafe4e-b2e3-43c9-b82c-dd35738a2d14",
   "metadata": {},
   "source": [
    "### Making Predictions on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8f5872f-0b3e-491d-8b95-2a6d1b9c03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Classify the test set using trained model & get the probabilities.\n",
    "arma::Row<size_t> output;\n",
    "arma::mat probs;\n",
    "dt.Classify(Xtest, output, probs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c88fed0-8b6a-402a-8ab7-0dce75aa13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Save the yTest and probabilities into csv for generating ROC AUC plot.\n",
    "data::Save(\"./data/probabilities.csv\", probs);\n",
    "data::Save(\"./data/ytest.csv\", Ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "897e60ff-6227-422e-9cae-a0f5f9d3b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n",
      "                    precision         recall       f1-score        support\n",
      "\n",
      "              0        0.93            0.89          0.91            2172\n",
      "              1         0.9            0.93          0.91            2243\n"
     ]
    }
   ],
   "source": [
    "// Model evaluation metrics.\n",
    "std::cout << \"Accuracy: \" << Accuracy(output, Ytest) << std::endl;\n",
    "ClassificationReport(output, Ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e2de4b4-ad63-4207-a501-0155c8edfe93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c4989f06a940f58bb4255e316c87c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 47c4989f06a940f58bb4255e316c87c0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Plot ROC AUC Curve to visualize the performance of the model on TP & FP.\n",
    "RocAucPlot(\"./data/ytest.csv\", \"./data/probabilities.csv\", \"Part-3 SMOTE ROC AUC Curve\");\n",
    "auto img = xw::image_from_file(\"./plots/Part-3 SMOTE ROC AUC Curve.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d23a8d-1d3a-4c10-9f03-e3d01dcd3adf",
   "metadata": {},
   "source": [
    "From the above classification report, we can infer that our model trained on SMOTE data performs well on both the classes. Also from the ROC AUC Curve, we can infer the True Positive Rate is around 90%, which is a quantifies that our model performs well on unseen data. But it performs slightly lower than the Oversampled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d1f0ac-61ba-4e2b-b5d6-28e213cba197",
   "metadata": {},
   "source": [
    "### Part 4 - Modelling using Random Undersampling\n",
    "For this part we would be handling the class imbalance by undersampling the majority class, to see how well our model trains and performs on randomly undersampled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b84661-4988-4e66-9005-f3041cbad33c",
   "metadata": {},
   "source": [
    "Since the size of the data set is quite small, undersampling of majority class would not make much sense here. But still we are going forward with this part to get a sense of how our model performs on less amount of data and it's impact on the learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f4d68ab-257c-4521-900b-6fd42bc8943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Undersample the majority class.\n",
    "Resample(\"LoanDefault.csv\", \"Defaulted?\", 0, 1, \"undersample\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "367f982e-6255-4936-af09-a0c0aaeecd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ef4a99fcab467496642602db73c185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 40ef4a99fcab467496642602db73c185"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Visualize the distribution of target classes.\n",
    "CountPlot(\"./data/LoanDefault_undersampled.csv\", \"Defaulted?\", \"\", \"Part-4 Distribution of target class\");\n",
    "auto img = xw::image_from_file(\"./plots/Part-4 Distribution of target class.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996923ab-8400-4fa0-b126-b2cf02dc7e62",
   "metadata": {},
   "source": [
    "From the above plot we can see that after resampling the majority class (No) is undersampled to be equal to the majority class (Yes). This solves our imbalanced data issue for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f335ab1c-0c8c-4c87-aba8-9b8567e923ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./data/LoanDefault_undersampled.csv | sed 1d > ./data/LoanDefault_trim.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7de7b7ae-3e6d-4545-8872-600ce45f4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Load the preprocessed dataset into armadillo matrix.\n",
    "arma::mat loanData;\n",
    "data::Load(\"./data/LoanDefault_trim.csv\", loanData);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7cec0eb0-89f7-4f88-b052-bf9cc7c89079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5381e23c83b84ddb88cec8b87e0d05ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 5381e23c83b84ddb88cec8b87e0d05ee"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Plot the correlation matrix as heatmap.\n",
    "HeatMapPlot(\"./data/LoanDefault_undersampled.csv\", \"coolwarm\", \"Part-4 Correlation Heatmap\", 1, 5, 5);\n",
    "auto img = xw::image_from_file(\"./plots/Part-4 Correlation Heatmap.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40119825-0637-4d60-bcd7-5cee37d81b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Split the data into features (X) and target (y) variables, targets are the last row.\n",
    "arma::Row<size_t> targets = arma::conv_to<arma::Row<size_t>>::from(loanData.row(loanData.n_rows - 1));\n",
    "// Targets are dropped from the loaded matrix.\n",
    "loanData.shed_row(loanData.n_rows-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f174a999-3646-4374-a015-2e28e130af7b",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "The dataset has to be split into training and test set. Here the dataset has 666 observations and the test ratio is taken as 20% of the total observations. This indicates that the test set should have 20% * 666 = 133 observations and training set should have 533 observations respectively. This can be done using the `data::Split()` api from mlpack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7cafef61-85dd-4339-bd5a-c2d6f2640a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Split the dataset into train and test sets using mlpack.\n",
    "arma::mat Xtrain, Xtest;\n",
    "arma::Row<size_t> Ytrain, Ytest;\n",
    "mlpack::data::Split(loanData, targets, Xtrain, Xtest, Ytrain, Ytest, 0.25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0307a7f-18e5-427d-86d8-e49b10393b84",
   "metadata": {},
   "source": [
    "### Training Decision Tree model\n",
    "We will use `DecisionTree<>` API from mlpack to train the model on SMOTE data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c79cf016-ef44-4810-a903-5c956e2971a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create and train Decision Tree model.\n",
    "DecisionTree<> dt(Xtrain, Ytrain, 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48c762fb-74a3-406c-8be0-dba47f9df8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Classify the test set using trained model & get the probabilities.\n",
    "arma::Row<size_t> output;\n",
    "arma::mat probs;\n",
    "dt.Classify(Xtest, output, probs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98a21f75-04f9-4f4e-a9b2-bd0afeda085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Save the yTest and probabilities into csv for generating ROC AUC plot.\n",
    "data::Save(\"./data/probabilities.csv\", probs);\n",
    "data::Save(\"./data/ytest.csv\", Ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ea6140a-cf16-4553-8dab-12c7130ac833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "                    precision         recall       f1-score        support\n",
      "\n",
      "              0        0.87             0.9          0.88              72\n",
      "              1         0.9            0.87          0.89              75\n"
     ]
    }
   ],
   "source": [
    "// Model evaluation metrics.\n",
    "std::cout << \"Accuracy: \" << Accuracy(output, Ytest) << std::endl;\n",
    "ClassificationReport(output, Ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b9fb89e6-1bf3-4e59-a409-2d5c761f1287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef733728eeb14a9f9b9d29b35e59f3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: ef733728eeb14a9f9b9d29b35e59f3a9"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Plot ROC AUC Curve to visualize the performance of the model on TP & FP.\n",
    "RocAucPlot(\"./data/ytest.csv\", \"./data/probabilities.csv\", \"Part-4 Random Undersampled targets ROC AUC Curve\");\n",
    "auto img = xw::image_from_file(\"./plots/Part-4 Random Undersampled targets ROC AUC Curve.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d48d66c-a9e4-48c4-85c3-184cce4252e7",
   "metadata": {},
   "source": [
    "From the above classification report, we can infer that our model trained on undersampled data performs well on both the classes compared to imbalanced model in Part 1. Also from the ROC AUC Curve, we can infer the True Positive Rate is around 80% although there is a small flatline, but still performs better than imbalanced model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509df61-cfa9-49ef-86ec-913b0dd3b3ed",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Models trained on resampled data performs well, but there is still room for improvement. Feel free to play around with the hyperparameters, training data split ratio etc. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
