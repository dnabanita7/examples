{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a02d85e-bfb1-4ef1-aa1c-819a4ecd60d5",
   "metadata": {},
   "source": [
    "### Micro Chip QA Classification using Naive Bayes Classifier\n",
    "\n",
    "### Our Objective\n",
    "* To reliably classify whether a micro chip is suitable for production usage, based on results of the quality tests.\n",
    "\n",
    "### Getting to know out MCQA dataset!\n",
    "Micro chip dataset contains only 3 features as follows:\n",
    "* Test_1 - Score quantifying the micro chip's performance on test 1.\n",
    "* Test_2 - Score quantifying the micro chip's performance on test 2.\n",
    "* QA_Passed - Target variable identifying if the mirco chip passed the test.\n",
    "\n",
    "### Approach\n",
    "* Initially we'll explore the dataset to check for imbalance & missing values.\n",
    "* Explore correlation between various features in the dataset.\n",
    "* Split the pre-processed dataset into train & test set respectively.\n",
    "* Create & train a Naive Bayes Classifier using mlpack.\n",
    "* We'll perform evaluation on our test set using various metrics to quantify the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d41b4-0d7f-46ce-9d2b-4104b868f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q http://datasets.mlpack.org/microChip.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "396dd5f0-9218-4512-931e-a7553472612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Import necessary library headers.\n",
    "#include <mlpack/xeus-cling.hpp>\n",
    "#include <mlpack/core.hpp>\n",
    "#include <mlpack/core/data/split_data.hpp>\n",
    "#include <mlpack/methods/naive_bayes/naive_bayes_classifier.hpp>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97d146d-5d4d-4dfc-8f43-2d745a80ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define WITHOUT_NUMPY 1\n",
    "#include \"matplotlibcpp.h\"\n",
    "#include \"xwidgets/ximage.hpp\"\n",
    "#include \"../utils/plot.hpp\"\n",
    "\n",
    "namespace plt = matplotlibcpp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b562ff-b276-46be-af69-726253e47ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace mlpack;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce95ba5f-b9fb-490d-a635-c08dd722f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace mlpack::data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88a0555a-3121-43ce-87d2-043ff2007deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace mlpack::naive_bayes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccbb4859-c37d-4dfd-b15c-ca7ee380e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Utility functions for evaluation metrics.\n",
    "double Accuracy(const arma::Row<size_t>& yPreds, const arma::Row<size_t>& yTrue)\n",
    "{\n",
    "    const size_t correct = arma::accu(yPreds == yTrue);\n",
    "    return (double)correct / (double)yTrue.n_elem;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96697d38-47bc-4f62-a48f-292b7516e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "double Precision(const size_t truePos, const size_t falsePos)\n",
    "{\n",
    "    return (double)truePos / (double)(truePos + falsePos);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "909a1235-e23c-44f0-afdb-7dd45e973e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "double Recall(const size_t truePos, const size_t falseNeg)\n",
    "{\n",
    "    return (double)truePos / (double)(truePos + falseNeg);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "614e5426-05a1-4d54-b4db-5b1af89de1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "double F1Score(const size_t truePos, const size_t falsePos, const size_t falseNeg)\n",
    "{\n",
    "    double prec = Precision(truePos, falsePos);\n",
    "    double rec = Precision(truePos, falseNeg);\n",
    "    return 2 * (prec * rec) / (prec + rec);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eede8c6f-6faa-4cbe-ba91-c76b431bd4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "void ClassificationReport(const arma::Row<size_t>& yPreds, const arma::Row<size_t>& yTrue)\n",
    "{\n",
    "    arma::Row<size_t> uniqs = arma::unique(yTrue);\n",
    "    std::cout << std::setw(29) << \"precision\" << std::setw(15) << \"recall\" \n",
    "              << std::setw(15) << \"f1-score\" << std::setw(15) << \"support\" \n",
    "              << std::endl << std::endl;\n",
    "    \n",
    "    for(auto val: uniqs)\n",
    "    {\n",
    "        size_t truePos = arma::accu(yTrue == val && yPreds == val && yPreds == yTrue);\n",
    "        size_t falsePos = arma::accu(yPreds == val && yPreds != yTrue);\n",
    "        size_t trueNeg = arma::accu(yTrue != val && yPreds != val && yPreds == yTrue);\n",
    "        size_t falseNeg = arma::accu(yPreds != val && yPreds != yTrue);\n",
    "        \n",
    "        std::cout << std::setw(15) << val\n",
    "                  << std::setw(12) << std::setprecision(2) << Precision(truePos, falsePos) \n",
    "                  << std::setw(16) << std::setprecision(2) << Recall(truePos, falseNeg) \n",
    "                  << std::setw(14) << std::setprecision(2) << F1Score(truePos, falsePos, falseNeg)\n",
    "                  << std::setw(16) << truePos\n",
    "                  << std::endl;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd8bb3fc-2bb7-4562-9a5c-b273eba7d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data && cat microChip.csv | sed 1d > ./data/microChip_trim.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad41ca02-cd45-443f-8963-086d41f9bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Load the preprocessed dataset into armadillo matrix.\n",
    "arma::mat microChipData;\n",
    "data::Load(\"./data/microChip_trim.csv\", microChipData);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2379b918-e415-43b2-bd75-988de92634fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test_1    Test_2    QA_Passed\n",
      "   34.6237   78.0247         0\n",
      "   30.2867   43.8950         0\n",
      "   35.8474   72.9022         0\n",
      "   60.1826   86.3086    1.0000\n",
      "   79.0327   75.3444    1.0000\n",
      "   45.0833   56.3164         0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Examine first 5 samples from our dataset.\n",
    "std::cout.precision(4);\n",
    "std::cout.setf(std::ios::fixed);\n",
    "std::cout << std::setw(10) << \"Test_1\" << std::setw(10) << \"Test_2\" << std::setw(13) << \"QA_Passed\" << std::endl;\n",
    "std::cout << microChipData.submat(0, 0, microChipData.n_rows-1, 5).t() << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "080137ed-33e4-48d9-b4b7-8cbb6a440c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5805baabceaf495cb75a58ee15a42ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 5805baabceaf495cb75a58ee15a42ff4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Plot the correlation matrix as a heatmap.\n",
    "HeatMapPlot(\"microChip.csv\", \"coolwarm\", \"Micro Chip Correlation Heatmap\", 1, 5, 5);\n",
    "auto img = xw::image_from_file(\"./plots/Micro Chip Correlation Heatmap.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b0a5e-43f3-486b-a1d5-03b47c616f6d",
   "metadata": {},
   "source": [
    "As we can infer from the above heatmap, there is some correlation between Test_1, Test_2 & QA_Passed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3a8c9b-b102-4578-9fd6-7b82cb37d868",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2fa7aa7-f28e-4d74-a2f7-8464cf825dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c39fe7cc0444a02a02fc5a1c43fa72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 2c39fe7cc0444a02a02fc5a1c43fa72d"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountPlot(\"microChip.csv\", \"QA_Passed\", \"\", \"Distribution of target class\");\n",
    "auto img = xw::image_from_file(\"./plots/Distribution of target class.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55707dec-ff69-4635-b27f-5c0adaf5e113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a0027ff76945a8bf56b1cd03765d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 70a0027ff76945a8bf56b1cd03765d1b"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PlotCatData(\"microChip.csv\", 2, \"Microchip Test 1\", \"Mircochip Test 2\", \"MCQA\");\n",
    "auto img = xw::image_from_file(\"./plots/MCQA.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "befe4a01-493c-4ac6-aa0e-c069e77ad77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Split the data into features (X) and target (y) variables, targets are the last row.\n",
    "arma::Row<size_t> targets = arma::conv_to<arma::Row<size_t>>::from(microChipData.row(microChipData.n_rows-1));\n",
    "// Targets are dropped from the loaded matrix.\n",
    "microChipData.shed_row(microChipData.n_rows-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30520e7-323f-48a7-81c9-8e9d3ae9f3a0",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "The dataset has to be split into training and test set. Here the dataset has 100 observations and the test ratio is taken as 25% of the total observations. This indicates that the test set should have 25% * 100 = 25 observations and training set should have 75 observations respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e607095f-c08e-4a35-a723-9ae154eb9aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Split the dataset into train and test sets using mlpack.\n",
    "arma::mat Xtrain, Xtest;\n",
    "arma::Row<size_t> Ytrain, Ytest;\n",
    "mlpack::data::Split(microChipData, targets, Xtrain, Xtest, Ytrain, Ytest, 0.25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce25737-cc50-400b-acac-165fbbdd0bf1",
   "metadata": {},
   "source": [
    "### Training the Naive Bayes Classifier\n",
    "Naive Bayes is a machine learning algorithm we use to solve classification problems. It is based on the Bayes Theorem. It is one of the simplest yet powerful ML algorithms and assumes that all predictors are independent.\n",
    "* It assumes that every feature is independent.\n",
    "* It gives every feature the same level of importance.\n",
    "\n",
    "$ P(Y|X) = \\frac{P(X|Y)P(Y)}{P(X)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e90cf3c3-89c5-4fe5-af9c-90f4f6846ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayesClassifier<> nbc(Xtrain, Ytrain, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6487e9c4-cd05-4536-a9e0-deaf5de871f5",
   "metadata": {},
   "source": [
    "### Making Predictions on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "709f7d14-b7d0-4546-9c89-c3102fa7507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Predict the values for test data using previously trained model as input.\n",
    "arma::Row<size_t> output;\n",
    "arma::mat probs;\n",
    "nbc.Classify(Xtest, output, probs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba358857-5af9-4b47-8365-61dc306d3602",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Save predicted probabilities and ground truth as csv for generating a ROC AUC curve.\n",
    "data::Save(\"./data/probabilities.csv\", probs);\n",
    "data::Save(\"./data/ytest.csv\", Ytest);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af98631d-cb6c-443f-9c2e-37919a3b166a",
   "metadata": {},
   "source": [
    "### Evaluation metrics\n",
    "\n",
    "* True Positive - The actual value was true & the model predicted true.\n",
    "* False Positive - The actual value was false & the model predicted true, Type I error.\n",
    "* True Negative - The actual value was false & the model predicted false.\n",
    "* False Negative - The actual value was true & the model predicted false, Type II error.\n",
    "\n",
    "`Accuracy`: is a metric that generally describes how the model performs across all classes. It is useful when all classes are of equal importance. It is calculated as the ratio between the number of correct predictions to the total number of predictions.\n",
    "\n",
    "$$Accuracy = \\frac{True_{positive} + True_{negative}}{True_{positive} + True_{negative} + False_{positive} + False_{negative}}$$\n",
    "\n",
    "`Precision`: is calculated as the ratio between the number of positive samples correctly classified to the total number of samples classified as Positive. The precision measures the model's accuracy in classifying a sample as positive.\n",
    "\n",
    "$$Precision = \\frac{True_{positive}}{True_{positive} + False_{positive}}$$\n",
    "\n",
    "`Recall`: is calulated as the ratio between the number of positive samples correctly classified as Positive to the total number of Positive samples. The recall measures the model's ability to detect Positive samples. The higher the recall, the more positive samples detected.\n",
    "\n",
    "$$Recall = \\frac{True_{positive}}{True_{positive} + False_{negative}}$$\n",
    "\n",
    "* The decision of whether to use precision or recall depends on the type of problem begin solved.\n",
    "* If the goal is to detect all positive samples then use recall.\n",
    "* Use precision if the problem is sensitive to classifying a sample as Positive in general.\n",
    "\n",
    "* ROC graph has the True Positive rate on the y axis and the False Positive rate on the x axis.\n",
    "* ROC Area under the curve in the graph is the primary metric to determine if the classifier is doing well, the higher the value the higher the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25ccf748-9035-46b6-a520-f23e3a376b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9200\n",
      "                    precision         recall       f1-score        support\n",
      "\n",
      "              0        1.00            0.82          0.90               9\n",
      "              1        0.88            1.00          0.93              14\n"
     ]
    }
   ],
   "source": [
    "// Classification report.\n",
    "std::cout << \"Accuracy: \" << Accuracy(output, Ytest) << std::endl;\n",
    "ClassificationReport(output, Ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3de43f41-b09d-4d5d-80d0-58bf1bc69569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac4fbc468684d5091ba60bb16ed1c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter widget with unique id: 1ac4fbc468684d5091ba60bb16ed1c23"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Plot ROC AUC Curve to visualize the performance of the model on TP & FP.\n",
    "RocAucPlot(\"./data/ytest.csv\", \"./data/probabilities.csv\", \"ROC AUC Curve\");\n",
    "auto img = xw::image_from_file(\"./plots/ROC AUC Curve.png\").finalize();\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7c2e50-50b6-4f4a-b512-ce352f61e14e",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "From the above classification report & ROC AUC, we can infer that our Naive Bayes Classifier model kinda performs well on our micro chip QA. Feel free to play around with h-params, split ratio etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
